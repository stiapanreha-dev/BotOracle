"""
Smart Messages Service - AI-generated system messages
Uses prompts from database to generate personalized system messages
"""
import logging
import json
import os
from typing import Dict, Any, Optional, List
from openai import OpenAI
import httpx

from app.database.connection import db

logger = logging.getLogger(__name__)


class SmartMessagesService:
    """Service for generating AI-powered system messages"""

    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("OPENAI_API_KEY not set, using stub responses")
            self.client = None
        else:
            # Check if SOCKS5 proxy is configured
            socks5_proxy = os.getenv("SOCKS5_PROXY")

            if socks5_proxy:
                logger.info(f"Configuring Smart Messages with SOCKS5 proxy: {socks5_proxy}")
                try:
                    from httpx_socks import SyncProxyTransport
                    transport = SyncProxyTransport.from_url(socks5_proxy)
                    http_client = httpx.Client(transport=transport, timeout=30.0)
                    self.client = OpenAI(api_key=api_key, http_client=http_client)
                except ImportError:
                    logger.error("httpx_socks not installed, falling back to direct connection")
                    self.client = OpenAI(api_key=api_key)
                except Exception as e:
                    logger.error(f"Error configuring SOCKS5 proxy: {e}, falling back to direct connection")
                    self.client = OpenAI(api_key=api_key)
            else:
                self.client = OpenAI(api_key=api_key)

    async def _get_prompt(self, key: str) -> Optional[str]:
        """Get prompt template from database"""
        try:
            row = await db.fetchrow(
                "SELECT prompt_text FROM ai_prompts WHERE key = $1 AND is_active = TRUE",
                key
            )
            if row:
                return row['prompt_text']
            logger.error(f"Prompt not found for key: {key}")
            return None
        except Exception as e:
            logger.error(f"Error fetching prompt {key}: {e}")
            return None

    async def _get_archetype_info(self, archetype_code: str) -> Dict[str, str]:
        """Get archetype information from database"""
        try:
            row = await db.fetchrow(
                "SELECT name_ru, description, communication_style FROM archetypes WHERE code = $1",
                archetype_code
            )
            if row:
                return {
                    'name': row['name_ru'],
                    'description': row['description'],
                    'communication_style': row['communication_style']
                }
            return {'name': 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹', 'description': '', 'communication_style': ''}
        except Exception as e:
            logger.error(f"Error fetching archetype {archetype_code}: {e}")
            return {'name': 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹', 'description': '', 'communication_style': ''}

    async def _call_openai(self, prompt: str, temperature: float = 0.7, json_mode: bool = False) -> str:
        """Call OpenAI API with given prompt"""
        if not self.client:
            return "AI unavailable"

        try:
            response_format = {"type": "json_object"} if json_mode else {"type": "text"}

            completion = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ğ¢Ñ‹ â€” AI-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Oracle Lounge. Ğ¡Ğ»ĞµĞ´ÑƒĞ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾."},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                response_format=response_format
            )

            return completion.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return "Error generating response"

    # ========================================================================
    # Welcome Messages
    # ========================================================================

    async def generate_welcome_message(self) -> str:
        """Generate welcome message for new user"""
        prompt = await self._get_prompt('welcome_new_user')
        if not prompt:
            return "ğŸ‘‹ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Oracle Lounge â€” Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ñ… Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ²."

        response = await self._call_openai(prompt, temperature=0.8)
        return response

    # ========================================================================
    # Onboarding Messages
    # ========================================================================

    async def generate_onboarding_questions(self) -> List[str]:
        """Generate 2 onboarding questions for archetype detection"""
        prompt = await self._get_prompt('onboarding_question_generator')
        if not prompt:
            return [
                "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒ: Ñ‚Ñ‹ Ğ¾ĞºĞ°Ğ·Ğ°Ğ»ÑÑ Ğ² ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ğ¸, Ğ³Ğ´Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ¾Ğ¹. Ğ§Ñ‚Ğ¾ Ğ±Ñ‹ Ñ‚Ñ‹ ÑĞ´ĞµĞ»Ğ°Ğ» Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ?",
                "Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ğ¸Ğ´ĞµÑ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ĞºĞ°Ğ¶ĞµÑ‚ÑÑ Ñ‚ĞµĞ±Ğµ Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğ¹, Ğ½Ğ¾ Ğ²ÑĞµ Ğ²Ğ¾ĞºÑ€ÑƒĞ³ ÑĞ¾Ğ¼Ğ½ĞµĞ²Ğ°ÑÑ‚ÑÑ. Ğ¢Ğ²Ğ¾Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ?"
            ]

        response = await self._call_openai(prompt, temperature=0.9)

        # Parse questions (separated by double newline)
        questions = [q.strip() for q in response.split('\n\n') if q.strip()]

        # Ensure we have exactly 2 questions
        if len(questions) != 2:
            logger.warning(f"Expected 2 questions, got {len(questions)}, using fallback")
            return [
                "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒ: Ñ‚Ñ‹ Ğ¾ĞºĞ°Ğ·Ğ°Ğ»ÑÑ Ğ² ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ğ¸, Ğ³Ğ´Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ¾Ğ¹. Ğ§Ñ‚Ğ¾ Ğ±Ñ‹ Ñ‚Ñ‹ ÑĞ´ĞµĞ»Ğ°Ğ» Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ?",
                "Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ğ¸Ğ´ĞµÑ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ĞºĞ°Ğ¶ĞµÑ‚ÑÑ Ñ‚ĞµĞ±Ğµ Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğ¹, Ğ½Ğ¾ Ğ²ÑĞµ Ğ²Ğ¾ĞºÑ€ÑƒĞ³ ÑĞ¾Ğ¼Ğ½ĞµĞ²Ğ°ÑÑ‚ÑÑ. Ğ¢Ğ²Ğ¾Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ?"
            ]

        return questions

    async def validate_onboarding_response(self, question: str, user_response: str) -> Dict[str, Any]:
        """Validate if user response is meaningful or trolling"""
        prompt_template = await self._get_prompt('onboarding_validate_response')
        if not prompt_template:
            # Simple fallback validation
            word_count = len(user_response.split())
            is_valid = word_count >= 5 and len(user_response) >= 20
            return {
                'is_valid': is_valid,
                'reason': 'ĞÑ‚Ğ²ĞµÑ‚ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹' if not is_valid else 'ĞÑ‚Ğ²ĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹'
            }

        prompt = prompt_template.format(question=question, user_response=user_response)
        response = await self._call_openai(prompt, temperature=0.5, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'is_valid': result.get('is_valid', False),
                'reason': result.get('reason', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse validation response: {response}")
            # Fallback
            word_count = len(user_response.split())
            is_valid = word_count >= 5
            return {
                'is_valid': is_valid,
                'reason': 'ĞÑ‚Ğ²ĞµÑ‚ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹' if not is_valid else 'ĞÑ‚Ğ²ĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹'
            }

    async def analyze_archetype(self, responses: List[Dict[str, str]]) -> Dict[str, Any]:
        """Analyze user responses and determine archetype"""
        prompt_template = await self._get_prompt('onboarding_archetype_analysis')
        if not prompt_template:
            # Fallback to random archetype
            return {
                'primary': 'hero',
                'secondary': 'sage',
                'confidence': 0.5,
                'explanation': 'ĞÑ€Ñ…ĞµÑ‚Ğ¸Ğ¿ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸'
            }

        # Format responses for analysis
        responses_text = "\n\n".join([
            f"Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ {i+1}: {r['question']}\nĞÑ‚Ğ²ĞµÑ‚: {r['response']}"
            for i, r in enumerate(responses)
        ])

        prompt = prompt_template.format(responses=responses_text)
        response = await self._call_openai(prompt, temperature=0.6, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'primary': result.get('primary', 'hero'),
                'secondary': result.get('secondary'),
                'confidence': result.get('confidence', 0.5),
                'explanation': result.get('explanation', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse archetype analysis: {response}")
            return {
                'primary': 'hero',
                'secondary': None,
                'confidence': 0.5,
                'explanation': 'ĞÑ€Ñ…ĞµÑ‚Ğ¸Ğ¿ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸'
            }

    async def generate_invalid_response_message(self, current_question: int, attempts_left: int) -> str:
        """Generate message for invalid/trolling response during onboarding"""
        prompt_template = await self._get_prompt('invalid_onboarding_response')
        if not prompt_template:
            if attempts_left > 0:
                return "Ğ¥Ğ¾Ñ‡ĞµÑ‚ÑÑ ÑƒÑĞ»Ñ‹ÑˆĞ°Ñ‚ÑŒ Ñ‚Ğ²Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ ğŸ˜Š Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ â€” ĞºĞ°Ğº Ğ±Ñ‹ Ñ‚Ñ‹ Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ¸Ğ» Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ?"
            return "ĞšĞ°Ğ¶ĞµÑ‚ÑÑ, ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ Ñ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ½Ğ° ÑĞµÑ€ÑŒÑ‘Ğ·Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€. ĞŸÑ€Ğ¸Ñ…Ğ¾Ğ´Ğ¸ Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ° â€” Ğ½Ğ°Ñ‡Ğ½Ñ‘Ğ¼ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾! ğŸ˜Š"

        prompt = prompt_template.format(current_question=current_question, attempts_left=attempts_left)
        response = await self._call_openai(prompt, temperature=0.7)
        return response

    async def generate_onboarding_final_message(self, archetype_code: str, confidence: float) -> str:
        """Generate final message after archetype determination"""
        prompt_template = await self._get_prompt('onboarding_final_message')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return f"Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ° Ğ¾Ñ‚ĞºÑ€Ğ¾Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ! Ğ¯ Ğ²Ğ¸Ğ¶Ñƒ Ğ² Ñ‚ĞµĞ±Ğµ {archetype_info['name']} â€” {archetype_info['description']}. Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ñ Ğ±ÑƒĞ´Ñƒ Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒÑÑ Ñ Ñ‚Ğ¾Ğ±Ğ¾Ğ¹ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ñ‚Ğ°Ğº, ĞºĞ°Ğº ÑÑ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ´Ğ»Ñ Ñ‚ĞµĞ±Ñ."

        prompt = prompt_template.format(
            archetype=archetype_code,
            archetype_name=archetype_info['name'],
            archetype_description=archetype_info['description'],
            confidence=confidence
        )

        response = await self._call_openai(prompt, temperature=0.7)
        return response

    # ========================================================================
    # Oracle Messages
    # ========================================================================

    async def generate_clarifying_questions(self, question: str, archetype_code: str) -> Dict[str, Any]:
        """Generate 1-2 clarifying questions before Oracle response"""
        prompt_template = await self._get_prompt('oracle_clarifying_questions')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return {
                'questions': ["Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ğ¸?"],
                'intro': ""
            }

        prompt = prompt_template.format(
            question=question,
            archetype=archetype_code,
            archetype_description=archetype_info['description'],
            communication_style=archetype_info['communication_style']
        )

        response = await self._call_openai(prompt, temperature=0.8, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'questions': result.get('questions', []),
                'intro': result.get('intro', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse clarifying questions: {response}")
            return {
                'questions': ["Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ğ¸?"],
                'intro': ""
            }

    # ========================================================================
    # System Messages
    # ========================================================================

    async def generate_error_message(self, error_type: str = "unknown") -> str:
        """Generate friendly error message"""
        prompt_template = await self._get_prompt('error_message')
        if not prompt_template:
            return "Ğ§Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ¿Ğ¾ÑˆĞ»Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº Ñ Ğ¼Ğ¾ĞµĞ¹ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ? ğŸ˜Š"

        prompt = prompt_template.format(error_type=error_type)
        response = await self._call_openai(prompt, temperature=0.8)
        return response

    async def generate_daily_message_intro(self, archetype_code: str, daily_text: str) -> str:
        """Generate intro for daily message based on archetype"""
        prompt_template = await self._get_prompt('daily_message_intro')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return f"Ğ”ĞµÑ€Ğ¶Ğ¸ Ğ¼Ñ‹ÑĞ»ÑŒ Ğ½Ğ° ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ:"

        prompt = prompt_template.format(
            archetype=archetype_code,
            archetype_description=archetype_info['description'],
            communication_style=archetype_info['communication_style'],
            daily_text=daily_text
        )

        response = await self._call_openai(prompt, temperature=0.7)
        return response


# Global instance
smart_messages = SmartMessagesService()


# Convenience functions
async def generate_welcome() -> str:
    return await smart_messages.generate_welcome_message()


async def generate_onboarding_questions() -> List[str]:
    return await smart_messages.generate_onboarding_questions()


async def validate_response(question: str, response: str) -> Dict[str, Any]:
    return await smart_messages.validate_onboarding_response(question, response)


async def analyze_archetype(responses: List[Dict[str, str]]) -> Dict[str, Any]:
    return await smart_messages.analyze_archetype(responses)


async def generate_clarifying_questions(question: str, archetype: str) -> Dict[str, Any]:
    return await smart_messages.generate_clarifying_questions(question, archetype)


async def generate_error_message(error_type: str = "unknown") -> str:
    return await smart_messages.generate_error_message(error_type)
