"""
Smart Messages Service - AI-generated system messages
Uses prompts from database to generate personalized system messages
"""
import logging
import json
import os
from typing import Dict, Any, Optional, List
from openai import OpenAI
import httpx

from app.database.connection import db

logger = logging.getLogger(__name__)


class SmartMessagesService:
    """Service for generating AI-powered system messages"""

    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("OPENAI_API_KEY not set, using stub responses")
            self.client = None
        else:
            # Check if SOCKS5 proxy is configured
            socks5_proxy = os.getenv("SOCKS5_PROXY")

            if socks5_proxy:
                logger.info(f"Configuring Smart Messages with SOCKS5 proxy: {socks5_proxy}")
                try:
                    from httpx_socks import SyncProxyTransport
                    transport = SyncProxyTransport.from_url(socks5_proxy)
                    http_client = httpx.Client(transport=transport, timeout=30.0)
                    self.client = OpenAI(api_key=api_key, http_client=http_client)
                except ImportError:
                    logger.error("httpx_socks not installed, falling back to direct connection")
                    self.client = OpenAI(api_key=api_key)
                except Exception as e:
                    logger.error(f"Error configuring SOCKS5 proxy: {e}, falling back to direct connection")
                    self.client = OpenAI(api_key=api_key)
            else:
                self.client = OpenAI(api_key=api_key)

    async def _get_prompt(self, key: str) -> Optional[str]:
        """Get prompt template from database"""
        try:
            row = await db.fetchrow(
                "SELECT prompt_text FROM ai_prompts WHERE key = $1 AND is_active = TRUE",
                key
            )
            if row:
                return row['prompt_text']
            logger.error(f"Prompt not found for key: {key}")
            return None
        except Exception as e:
            logger.error(f"Error fetching prompt {key}: {e}")
            return None

    async def _get_archetype_info(self, archetype_code: str) -> Dict[str, str]:
        """Get archetype information from database"""
        try:
            row = await db.fetchrow(
                "SELECT name_ru, description, communication_style FROM archetypes WHERE code = $1",
                archetype_code
            )
            if row:
                return {
                    'name': row['name_ru'],
                    'description': row['description'],
                    'communication_style': row['communication_style']
                }
            return {'name': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π', 'description': '', 'communication_style': ''}
        except Exception as e:
            logger.error(f"Error fetching archetype {archetype_code}: {e}")
            return {'name': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π', 'description': '', 'communication_style': ''}

    async def _call_openai(self, prompt: str, temperature: float = 0.7, json_mode: bool = False) -> str:
        """Call OpenAI API with given prompt"""
        if not self.client:
            return "AI unavailable"

        try:
            response_format = {"type": "json_object"} if json_mode else {"type": "text"}

            completion = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "–¢—ã ‚Äî AI-–ø–æ–º–æ—â–Ω–∏–∫ Oracle Lounge. –°–ª–µ–¥—É–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º —Ç–æ—á–Ω–æ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                response_format=response_format
            )

            return completion.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return "Error generating response"

    # ========================================================================
    # Welcome Messages
    # ========================================================================

    async def generate_welcome_message(self) -> str:
        """Generate welcome message for new user"""
        prompt = await self._get_prompt('welcome_new_user')
        if not prompt:
            return "üëã –ü—Ä–∏–≤–µ—Ç! –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Oracle Lounge ‚Äî –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤."

        response = await self._call_openai(prompt, temperature=0.8)
        return response

    # ========================================================================
    # Onboarding Messages
    # ========================================================================

    async def generate_onboarding_questions(self, age: int, gender: str) -> List[str]:
        """Generate 2 onboarding questions for archetype detection (adapted to age/gender)"""
        prompt_template = await self._get_prompt('onboarding_question_generator')
        if not prompt_template:
            return [
                "–ü—Ä–µ–¥—Å—Ç–∞–≤—å: —Ç—ã –æ–∫–∞–∑–∞–ª—Å—è –≤ —Å–∏—Ç—É–∞—Ü–∏–∏, –≥–¥–µ –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–µ–∂–¥—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –∏ —Å–≤–æ–±–æ–¥–æ–π. –ß—Ç–æ –±—ã —Ç—ã —Å–¥–µ–ª–∞–ª –∏ –ø–æ—á–µ–º—É?",
                "–£ —Ç–µ–±—è –µ—Å—Ç—å –∏–¥–µ—è, –∫–æ—Ç–æ—Ä–∞—è –∫–∞–∂–µ—Ç—Å—è —Ç–µ–±–µ –≤–∞–∂–Ω–æ–π, –Ω–æ –≤—Å–µ –≤–æ–∫—Ä—É–≥ —Å–æ–º–Ω–µ–≤–∞—é—Ç—Å—è. –¢–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è?"
            ]

        # Format prompt with user context
        prompt = prompt_template.format(age=age, gender=gender)
        response = await self._call_openai(prompt, temperature=0.9)

        # Parse questions (separated by double newline)
        questions = [q.strip() for q in response.split('\n\n') if q.strip()]

        # Ensure we have at least 2 questions, take first 2
        if len(questions) < 2:
            logger.warning(f"Expected at least 2 questions, got {len(questions)}, using fallback")
            return [
                "–ü—Ä–µ–¥—Å—Ç–∞–≤—å: —Ç—ã –æ–∫–∞–∑–∞–ª—Å—è –≤ —Å–∏—Ç—É–∞—Ü–∏–∏, –≥–¥–µ –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–µ–∂–¥—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –∏ —Å–≤–æ–±–æ–¥–æ–π. –ß—Ç–æ –±—ã —Ç—ã —Å–¥–µ–ª–∞–ª –∏ –ø–æ—á–µ–º—É?",
                "–£ —Ç–µ–±—è –µ—Å—Ç—å –∏–¥–µ—è, –∫–æ—Ç–æ—Ä–∞—è –∫–∞–∂–µ—Ç—Å—è —Ç–µ–±–µ –≤–∞–∂–Ω–æ–π, –Ω–æ –≤—Å–µ –≤–æ–∫—Ä—É–≥ —Å–æ–º–Ω–µ–≤–∞—é—Ç—Å—è. –¢–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è?"
            ]

        return questions[:2]  # Take first 2 questions

    async def validate_onboarding_response(self, question: str, user_response: str) -> Dict[str, Any]:
        """Validate if user response is meaningful or trolling"""
        prompt_template = await self._get_prompt('onboarding_validate_response')
        if not prompt_template:
            # Simple fallback validation
            word_count = len(user_response.split())
            is_valid = word_count >= 5 and len(user_response) >= 20
            return {
                'is_valid': is_valid,
                'reason': '–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π' if not is_valid else '–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π'
            }

        prompt = prompt_template.format(question=question, user_response=user_response)
        response = await self._call_openai(prompt, temperature=0.5, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'is_valid': result.get('is_valid', False),
                'reason': result.get('reason', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse validation response: {response}")
            # Fallback
            word_count = len(user_response.split())
            is_valid = word_count >= 5
            return {
                'is_valid': is_valid,
                'reason': '–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π' if not is_valid else '–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π'
            }

    async def analyze_archetype(self, responses: List[Dict[str, str]]) -> Dict[str, Any]:
        """Analyze user responses and determine archetype"""
        prompt_template = await self._get_prompt('onboarding_archetype_analysis')
        if not prompt_template:
            # Fallback to random archetype
            return {
                'primary': 'hero',
                'secondary': 'sage',
                'confidence': 0.5,
                'explanation': '–ê—Ä—Ö–µ—Ç–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏'
            }

        # Format responses for analysis
        responses_text = "\n\n".join([
            f"–í–æ–ø—Ä–æ—Å {i+1}: {r['question']}\n–û—Ç–≤–µ—Ç: {r['response']}"
            for i, r in enumerate(responses)
        ])

        prompt = prompt_template.format(responses=responses_text)
        response = await self._call_openai(prompt, temperature=0.6, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'primary': result.get('primary', 'hero'),
                'secondary': result.get('secondary'),
                'confidence': result.get('confidence', 0.5),
                'explanation': result.get('explanation', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse archetype analysis: {response}")
            return {
                'primary': 'hero',
                'secondary': None,
                'confidence': 0.5,
                'explanation': '–ê—Ä—Ö–µ—Ç–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏'
            }

    async def generate_invalid_response_message(self, current_question: int, attempts_left: int) -> str:
        """Generate message for invalid/trolling response during onboarding"""
        prompt_template = await self._get_prompt('invalid_onboarding_response')
        if not prompt_template:
            if attempts_left > 0:
                return "–•–æ—á–µ—Ç—Å—è —É—Å–ª—ã—à–∞—Ç—å —Ç–≤–æ–π –Ω–∞—Å—Ç–æ—è—â–∏–π –æ—Ç–≤–µ—Ç üòä –†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî –∫–∞–∫ –±—ã —Ç—ã –ø–æ—Å—Ç—É–ø–∏–ª –∏ –ø–æ—á–µ–º—É?"
            return "–ö–∞–∂–µ—Ç—Å—è, —Å–µ–≥–æ–¥–Ω—è —Ç—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ —Å–µ—Ä—å—ë–∑–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä. –ü—Ä–∏—Ö–æ–¥–∏ –∑–∞–≤—Ç—Ä–∞ ‚Äî –Ω–∞—á–Ω—ë–º –∑–∞–Ω–æ–≤–æ! üòä"

        prompt = prompt_template.format(current_question=current_question, attempts_left=attempts_left)
        response = await self._call_openai(prompt, temperature=0.7)
        return response

    async def generate_onboarding_final_message(self, archetype_code: str, confidence: float) -> str:
        """Generate final message after archetype determination"""
        prompt_template = await self._get_prompt('onboarding_final_message')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return f"–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–æ—Å—Ç—å! –Ø –≤–∏–∂—É –≤ —Ç–µ–±–µ {archetype_info['name']} ‚Äî {archetype_info['description']}. –¢–µ–ø–µ—Ä—å —è –±—É–¥—É –æ–±—â–∞—Ç—å—Å—è —Å —Ç–æ–±–æ–π –∏–º–µ–Ω–Ω–æ —Ç–∞–∫, –∫–∞–∫ —ç—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ–±—è."

        prompt = prompt_template.format(
            archetype=archetype_code,
            archetype_name=archetype_info['name'],
            archetype_description=archetype_info['description'],
            confidence=confidence
        )

        response = await self._call_openai(prompt, temperature=0.7)
        return response

    # ========================================================================
    # Oracle Messages
    # ========================================================================

    async def generate_clarifying_questions(self, question: str, archetype_code: str) -> Dict[str, Any]:
        """Generate 1-2 clarifying questions before Oracle response"""
        prompt_template = await self._get_prompt('oracle_clarifying_questions')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return {
                'questions': ["–†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–∏—Ç—É–∞—Ü–∏–∏?"],
                'intro': ""
            }

        prompt = prompt_template.format(
            question=question,
            archetype=archetype_code,
            archetype_description=archetype_info['description'],
            communication_style=archetype_info['communication_style']
        )

        response = await self._call_openai(prompt, temperature=0.8, json_mode=True)

        try:
            result = json.loads(response)
            return {
                'questions': result.get('questions', []),
                'intro': result.get('intro', '')
            }
        except json.JSONDecodeError:
            logger.error(f"Failed to parse clarifying questions: {response}")
            return {
                'questions': ["–†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–∏—Ç—É–∞—Ü–∏–∏?"],
                'intro': ""
            }

    # ========================================================================
    # CRM Messages
    # ========================================================================

    async def generate_crm_message(self, task_type: str, user_context: Dict[str, Any]) -> str:
        """Generate personalized CRM message based on task type and user context"""
        # Map task types to prompt keys
        prompt_key_map = {
            'PING': 'crm_ping',
            'NUDGE_SUB': 'crm_nudge_sub',
            'RECOVERY': 'crm_recovery',
            'LIMIT_INFO': 'crm_limit_info',
            'THANKS': 'crm_thanks'
        }

        prompt_key = prompt_key_map.get(task_type)
        if not prompt_key:
            logger.warning(f"Unknown task type for CRM generation: {task_type}")
            return "–ø—Ä–∏–≤–µ—Ç! —è –∑–¥–µ—Å—å, –µ—Å–ª–∏ —á—Ç–æ –Ω—É–∂–Ω–æ üåü"

        prompt_template = await self._get_prompt(prompt_key)
        if not prompt_template:
            # Fallback messages for each type
            fallbacks = {
                'PING': "–ø—Ä–∏–≤–µ—Ç! –∫–∞–∫ —É —Ç–µ–±—è –¥–µ–ª–∞? üòä",
                'NUDGE_SUB': "—Ö–æ—á–µ—à—å –±–æ–ª—å—à–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –û—Ä–∞–∫—É–ª—É? –ø–æ–ø—Ä–æ–±—É–π –ø—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫—É üíé",
                'RECOVERY': "–¥–∞–≤–Ω–æ —Ç–µ–±—è –Ω–µ –≤–∏–¥–µ–ª–∞! –∫–∞–∫ —Ç—ã? üåü",
                'LIMIT_INFO': "—É —Ç–µ–±—è –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ –û—Ä–∞–∫—É–ª—É. —Ö–æ—á–µ—à—å –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø? üîÆ",
                'THANKS': "—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–≤–æ–π –≤–æ–ø—Ä–æ—Å! üí´"
            }
            return fallbacks.get(task_type, "–ø—Ä–∏–≤–µ—Ç! üòä")

        # Get archetype info if available
        archetype_code = user_context.get('archetype_primary', 'hero')
        archetype_info = await self._get_archetype_info(archetype_code)

        # Format prompt with all context
        prompt = prompt_template.format(
            age=user_context.get('age', 25),
            gender=user_context.get('gender', 'unknown'),
            archetype=archetype_code,
            archetype_name=archetype_info['name'],
            archetype_description=archetype_info['description'],
            communication_style=archetype_info['communication_style'],
            tone=user_context.get('tone', 'friendly'),
            remaining=user_context.get('remaining', 0)
        )

        response = await self._call_openai(prompt, temperature=0.9)
        return response.strip()

    # ========================================================================
    # System Messages
    # ========================================================================

    async def generate_error_message(self, error_type: str = "unknown") -> str:
        """Generate friendly error message"""
        prompt_template = await self._get_prompt('error_message')
        if not prompt_template:
            return "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å –º–æ–µ–π —Å—Ç–æ—Ä–æ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É? üòä"

        prompt = prompt_template.format(error_type=error_type)
        response = await self._call_openai(prompt, temperature=0.8)
        return response

    async def generate_daily_message_intro(self, archetype_code: str, daily_text: str) -> str:
        """Generate intro for daily message based on archetype"""
        prompt_template = await self._get_prompt('daily_message_intro')
        archetype_info = await self._get_archetype_info(archetype_code)

        if not prompt_template:
            return f"–î–µ—Ä–∂–∏ –º—ã—Å–ª—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:"

        prompt = prompt_template.format(
            archetype=archetype_code,
            archetype_description=archetype_info['description'],
            communication_style=archetype_info['communication_style'],
            daily_text=daily_text
        )

        response = await self._call_openai(prompt, temperature=0.7)
        return response


# Global instance
smart_messages = SmartMessagesService()


# Convenience functions
async def generate_welcome() -> str:
    return await smart_messages.generate_welcome_message()


async def generate_onboarding_questions(age: int, gender: str) -> List[str]:
    return await smart_messages.generate_onboarding_questions(age, gender)


async def validate_response(question: str, response: str) -> Dict[str, Any]:
    return await smart_messages.validate_onboarding_response(question, response)


async def analyze_archetype(responses: List[Dict[str, str]]) -> Dict[str, Any]:
    return await smart_messages.analyze_archetype(responses)


async def generate_clarifying_questions(question: str, archetype: str) -> Dict[str, Any]:
    return await smart_messages.generate_clarifying_questions(question, archetype)


async def generate_error_message(error_type: str = "unknown") -> str:
    return await smart_messages.generate_error_message(error_type)


async def generate_crm_message(task_type: str, user_context: Dict[str, Any]) -> str:
    return await smart_messages.generate_crm_message(task_type, user_context)
